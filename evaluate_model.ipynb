{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94cd9f52",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "We will be evaluating two models. A base Llama 3.2 Instruct model (on zero-shot and ICL) and a fine-tuned Llama 3.2 Instruct model (zero-shot). All models are run locally on my machine via KoboldCPP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e11b54e",
   "metadata": {},
   "source": [
    "# Precision\n",
    "We will evaluate both models for precision. Let's first test the base model with zero shot context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6c44f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d138ef992fa4c9c9776f478e1e14073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d535dcda6cf49db8bf4b47c7aad5a3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "\n",
    "precision = evaluate.load(\"precision\")\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "dataset = load_dataset(\"json\", data_files=\"test.jsonl\")\n",
    "\n",
    "inputs = [_input for _input in dataset[\"train\"][\"text\"]] # The inputs going to the LLM.\n",
    "references = [label for label in dataset[\"train\"][\"label\"]] # This is the real expected value from the test dataset.\n",
    "\n",
    "# Instruct special tokens specifically for Llama\n",
    "system_tag = \"<|start_header_id|>system<|end_header_id|>\\n\\n\"\n",
    "user_tag = \"<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n\"\n",
    "assistant_tag = \"<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\"\n",
    "\n",
    "instruction_prompt = system_tag + \"Determine if the user's sentiment is 0 (negative), 1 (neutral), or 2 (positive). \" \\\n",
    "\"Your response should only be a number and nothing else.\\n\"\n",
    "\n",
    "# koboldcpp endpoint\n",
    "KOBOLD_ENDPOINT = \"http://127.0.0.1:5001/api/v1/generate\" # this is specifically the base model's raw text completion. NOT CHAT COMPLETIONS!\n",
    "FT_KOBOLD_ENDPOINT = \"http://127.0.0.1:5002/api/v1/generate\" # the fine-tuned model's endpoint\n",
    "\n",
    "# Sampler settings\n",
    "max_length = 3\n",
    "temperature = 0.1\n",
    "stop_sequence = [\"\\n\", \"<|eot_id|>\", \"<\"]\n",
    "memory = instruction_prompt\n",
    "grammar = \"root ::= \\\"0\\\" | \\\"1\\\" | \\\"2\\\"\" # gbnf grammar to force the model to only output 0, 1, or 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b0d055",
   "metadata": {},
   "source": [
    "### Base Model (Zero Shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8a466c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.29376716233483574}\n",
      "{'accuracy': 0.32068965517241377}\n",
      "{'f1': 0.26545814736312784}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for _input in inputs:\n",
    "    prompt = user_tag + _input + assistant_tag\n",
    "    body = {\n",
    "        \"memory\": memory,\n",
    "        \"prompt\": prompt,\n",
    "        \"temperature\": temperature,\n",
    "        \"max_length\": max_length,\n",
    "        \"stop_sequence\": stop_sequence,\n",
    "        \"grammar\": grammar\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(KOBOLD_ENDPOINT, json=body)\n",
    "    except Exception as e:\n",
    "        raise BaseException(\"Could not get response from kobold. Are you sure it's on and running?\")\n",
    "    \n",
    "    predictions.append(response.json()[\"results\"][0][\"text\"])\n",
    "\n",
    "prec_result = precision.compute(references=references, predictions=predictions, average=\"macro\")\n",
    "acc_result = accuracy.compute(references=references, predictions=predictions)\n",
    "f1_result = f1.compute(references=references, predictions=predictions, average=\"macro\")\n",
    "print(prec_result)\n",
    "print(acc_result)\n",
    "print(f1_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff18206",
   "metadata": {},
   "source": [
    "### Base Model (Few Shot)\n",
    "We will be testing one-shot and three-shot example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e0db18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1 results:\n",
      "{'precision': 0.39284272169210915}\n",
      "{'accuracy': 0.38550057537399307}\n",
      "{'f1': 0.3697208223816504}\n",
      "k=3 results:\n",
      "{'precision': 0.4013540809863299}\n",
      "{'accuracy': 0.39677047289504036}\n",
      "{'f1': 0.36036137031177146}\n"
     ]
    }
   ],
   "source": [
    "def eval_k_shot(k: int):\n",
    "    predictions = []\n",
    "    examples = \"Examples:\\n\"\n",
    "\n",
    "    for example, output in zip(inputs[:k], references[:k]):\n",
    "        examples += f\"\\\"{example}\\\" => {output}\\n\\n\"\n",
    "\n",
    "    many_shot_system_prompt = instruction_prompt + \"\\n\\n\" + examples\n",
    "\n",
    "    for _input in inputs[k:]:\n",
    "        prompt = user_tag + _input + assistant_tag\n",
    "        body = {\n",
    "            \"memory\": many_shot_system_prompt,\n",
    "            \"prompt\": prompt,\n",
    "            \"temperature\": temperature,\n",
    "            \"max_length\": max_length,\n",
    "            \"stop_sequence\": stop_sequence,\n",
    "            \"grammar\": grammar\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.post(KOBOLD_ENDPOINT, json=body)\n",
    "        except Exception as e:\n",
    "            raise BaseException(\"Could not get response from kobold. Are you sure it's on and running?\")\n",
    "        \n",
    "        predictions.append(response.json()[\"results\"][0][\"text\"])\n",
    "\n",
    "    prec_result = precision.compute(references=references[k:], predictions=predictions, average=\"macro\")\n",
    "    acc_result = accuracy.compute(references=references[k:], predictions=predictions)\n",
    "    f1_result = f1.compute(references=references[k:], predictions=predictions, average=\"macro\")\n",
    "    print(f\"k={k} results:\")\n",
    "    print(prec_result)\n",
    "    print(acc_result)\n",
    "    print(f1_result)\n",
    "\n",
    "eval_k_shot(1)\n",
    "eval_k_shot(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f44748",
   "metadata": {},
   "source": [
    "### Fine-tuned (Zero-shot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f8e066f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': 0.6630550119133632}\n",
      "{'accuracy': 0.6609195402298851}\n",
      "{'f1': 0.6545950025155124}\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "\n",
    "for _input in inputs:\n",
    "    prompt = user_tag + _input + assistant_tag\n",
    "    body = {\n",
    "        \"memory\": memory,\n",
    "        \"prompt\": prompt,\n",
    "        \"temperature\": temperature,\n",
    "        \"max_length\": max_length,\n",
    "        \"stop_sequence\": stop_sequence,\n",
    "        \"grammar\": grammar\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(FT_KOBOLD_ENDPOINT, json=body)\n",
    "    except Exception as e:\n",
    "        raise BaseException(\"Could not get response from kobold. Are you sure it's on and running?\")\n",
    "    \n",
    "    predictions.append(response.json()[\"results\"][0][\"text\"])\n",
    "\n",
    "prec_result = precision.compute(references=references, predictions=predictions, average=\"macro\")\n",
    "acc_result = accuracy.compute(references=references, predictions=predictions)\n",
    "f1_result = f1.compute(references=references, predictions=predictions, average=\"macro\")\n",
    "print(prec_result)\n",
    "print(acc_result)\n",
    "print(f1_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-class-training-model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
